{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pPeEPamcQmR",
        "outputId": "66421f91-73b1-4871-b8a4-8a05436919d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Scraping: http://books.toscrape.com/catalogue/page-1.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-2.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-3.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-4.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-5.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-6.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-7.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-8.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-9.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-10.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-11.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-12.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-13.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-14.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-15.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-16.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-17.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-18.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-19.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-20.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-21.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-22.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-23.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-24.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-25.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-26.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-27.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-28.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-29.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-30.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-31.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-32.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-33.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-34.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-35.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-36.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-37.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-38.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-39.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-40.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-41.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-42.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-43.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-44.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-45.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-46.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-47.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-48.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-49.html\n",
            "Scraping: http://books.toscrape.com/catalogue/page-50.html\n",
            "\n",
            "Scraping complete! Data saved to books.csv.\n",
            "                                   Title    Price Availability Star Rating\n",
            "0                   A Light in the Attic  Â£51.77     In stock       Three\n",
            "1                     Tipping the Velvet  Â£53.74     In stock         One\n",
            "2                             Soumission  Â£50.10     In stock         One\n",
            "3                          Sharp Objects  Â£47.82     In stock        Four\n",
            "4  Sapiens: A Brief History of Humankind  Â£54.23     In stock        Five\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#q1\n",
        "!pip install requests beautifulsoup4 pandas\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "def scrape_books():\n",
        "    base_url = \"http://books.toscrape.com/catalogue/\"\n",
        "    current_page_url = base_url + \"page-1.html\"\n",
        "    all_books_data = []\n",
        "\n",
        "    while current_page_url:\n",
        "        print(f\"Scraping: {current_page_url}\")\n",
        "        try:\n",
        "            response = requests.get(current_page_url)\n",
        "            response.raise_for_status()\n",
        "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "            books = soup.find_all(\"article\", class_=\"product_pod\")\n",
        "\n",
        "            for book in books:\n",
        "                title = book.h3.a[\"title\"]\n",
        "                price = book.find(\"p\", class_=\"price_color\").text\n",
        "                availability = book.find(\"p\", class_=\"instock availability\").text.strip()\n",
        "\n",
        "\n",
        "                rating = book.find(\"p\", class_=\"star-rating\")[\"class\"][1]\n",
        "\n",
        "                all_books_data.append({\n",
        "                    \"Title\": title,\n",
        "                    \"Price\": price,\n",
        "                    \"Availability\": availability,\n",
        "                    \"Star Rating\": rating\n",
        "                })\n",
        "\n",
        "            next_button = soup.find(\"li\", class_=\"next\")\n",
        "            if next_button:\n",
        "                next_page_relative_url = next_button.a[\"href\"]\n",
        "                current_page_url = base_url + next_page_relative_url\n",
        "            else:\n",
        "                current_page_url = None\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "            break\n",
        "\n",
        "    return all_books_data\n",
        "\n",
        "books_data = scrape_books()\n",
        "\n",
        "if books_data:\n",
        "    df = pd.DataFrame(books_data)\n",
        "    df.to_csv(\"books.csv\", index=False)\n",
        "    print(\"\\nScraping complete! Data saved to books.csv.\")\n",
        "    print(df.head())\n",
        "else:\n",
        "    print(\"No data was scraped.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#q2\n",
        "\n",
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
        "import pandas as pd\n",
        "\n",
        "def setup_driver():\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument('--headless')\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "    options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')\n",
        "    return webdriver.Chrome(options=options)\n",
        "\n",
        "def scrape_imdb_robust():\n",
        "    url = \"https://www.imdb.com/chart/top/\"\n",
        "    driver = setup_driver()\n",
        "    all_movies_data = []\n",
        "\n",
        "    try:\n",
        "        print(\"Fetching IMDB Top 250 page...\")\n",
        "        driver.get(url)\n",
        "\n",
        "\n",
        "        wait = WebDriverWait(driver, 20)\n",
        "        movie_elements = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"div.ipc-metadata-list-summary-item__c\")))\n",
        "\n",
        "        print(f\"Successfully located {len(movie_elements)} movie containers. Starting scrape...\")\n",
        "\n",
        "        for element in movie_elements:\n",
        "            try:\n",
        "                title_text = element.find_element(By.CSS_SELECTOR, \"h3.ipc-title__text\").text\n",
        "                rank_str, title = title_text.split('. ', 1)\n",
        "\n",
        "                metadata_items = element.find_elements(By.CSS_SELECTOR, \"span.cli-title-metadata-item\")\n",
        "                year = metadata_items[0].text if metadata_items else \"N/A\"\n",
        "\n",
        "                rating_span = element.find_element(By.CSS_SELECTOR, \"span.ipc-rating-star\")\n",
        "                rating = rating_span.text.split()[0]\n",
        "\n",
        "                all_movies_data.append({\n",
        "                    \"Rank\": int(rank_str),\n",
        "                    \"Movie Title\": title,\n",
        "                    \"Year of Release\": year,\n",
        "                    \"IMDB Rating\": float(rating)\n",
        "                })\n",
        "            except (NoSuchElementException, IndexError, ValueError):\n",
        "                continue\n",
        "\n",
        "    except TimeoutException:\n",
        "        print(\"Scraping failed: The movie list did not load within the 20-second time limit.\")\n",
        "        print(\"The website structure has likely changed, or anti-scraping measures are blocking the script.\")\n",
        "    except Exception as e:\n",
        "        print(f\"A critical error occurred: {e}\")\n",
        "    finally:\n",
        "        driver.quit()\n",
        "\n",
        "    return all_movies_data\n",
        "\n",
        "imdb_data = scrape_imdb_robust()\n",
        "\n",
        "if imdb_data:\n",
        "    df = pd.DataFrame(imdb_data)\n",
        "    df.to_csv(\"imdb_top250.csv\", index=False)\n",
        "    print(f\"\\nScraping complete! Found {len(imdb_data)} movies. Data saved to imdb_top250.csv.\")\n",
        "    print(df.head())\n",
        "else:\n",
        "    print(\"\\nNo data was scraped from IMDB.\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WylKvT52c7DN",
        "outputId": "e01e270a-4ac0-4875-b286-a8b0798fbade"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.12/dist-packages (4.38.0)\n",
            "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
            "Requirement already satisfied: trio<1.0,>=0.31.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.32.0)\n",
            "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.10.5 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.11.12)\n",
            "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (4.15.0)\n",
            "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.9.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (25.4.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (3.11)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.12/dist-packages (from trio-websocket<1.0,>=0.12.2->selenium) (1.3.2)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
            "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://cli.github.com/packages stable InRelease\n",
            "Hit:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (1:85.0.4183.83-0ubuntu2.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 53 not upgraded.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SessionNotCreatedException",
          "evalue": "Message: session not created: Chrome instance exited. Examine ChromeDriver verbose log to determine the cause.; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#sessionnotcreatedexception\nStacktrace:\n#0 0x55b36838d4ca <unknown>\n#1 0x55b367ddbe4b <unknown>\n#2 0x55b367e16919 <unknown>\n#3 0x55b367e12375 <unknown>\n#4 0x55b367e62fe6 <unknown>\n#5 0x55b367e62706 <unknown>\n#6 0x55b367e20c2a <unknown>\n#7 0x55b367e21931 <unknown>\n#8 0x55b368353cf9 <unknown>\n#9 0x55b368356cdc <unknown>\n#10 0x55b36833cf79 <unknown>\n#11 0x55b3683578b5 <unknown>\n#12 0x55b3683249c3 <unknown>\n#13 0x55b36837a228 <unknown>\n#14 0x55b36837a403 <unknown>\n#15 0x55b36838c463 <unknown>\n#16 0x7f0516460ac3 <unknown>\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSessionNotCreatedException\u001b[0m                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3605327136.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mall_movies_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mimdb_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_imdb_robust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mimdb_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3605327136.py\u001b[0m in \u001b[0;36mscrape_imdb_robust\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscrape_imdb_robust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://www.imdb.com/chart/top/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mall_movies_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3605327136.py\u001b[0m in \u001b[0;36msetup_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscrape_imdb_robust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/selenium/webdriver/chrome/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mbrowser_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDesiredCapabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHROME\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"browserName\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mvendor_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"goog\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/selenium/webdriver/chromium/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, command_executor, keep_alive, file_detector, options, locator_converter, web_element_cls, client_config)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_authenticator_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fedcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFedCM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mstart_session\u001b[0;34m(self, capabilities)\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mcaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_caps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEW_SESSION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sessionId\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"capabilities\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alert\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mSessionNotCreatedException\u001b[0m: Message: session not created: Chrome instance exited. Examine ChromeDriver verbose log to determine the cause.; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#sessionnotcreatedexception\nStacktrace:\n#0 0x55b36838d4ca <unknown>\n#1 0x55b367ddbe4b <unknown>\n#2 0x55b367e16919 <unknown>\n#3 0x55b367e12375 <unknown>\n#4 0x55b367e62fe6 <unknown>\n#5 0x55b367e62706 <unknown>\n#6 0x55b367e20c2a <unknown>\n#7 0x55b367e21931 <unknown>\n#8 0x55b368353cf9 <unknown>\n#9 0x55b368356cdc <unknown>\n#10 0x55b36833cf79 <unknown>\n#11 0x55b3683578b5 <unknown>\n#12 0x55b3683249c3 <unknown>\n#13 0x55b36837a228 <unknown>\n#14 0x55b36837a403 <unknown>\n#15 0x55b36838c463 <unknown>\n#16 0x7f0516460ac3 <unknown>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#q3\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "def scrape_weather():\n",
        "    url = \"https://www.timeanddate.com/weather/\"\n",
        "    response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "    response.raise_for_status()\n",
        "\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    all_weather_data = []\n",
        "\n",
        "\n",
        "    table = soup.find(\"table\", class_=\"zebra fw tb-theme\")\n",
        "    rows = table.find_all(\"tr\")\n",
        "\n",
        "    for row in rows[1:]:\n",
        "        cols = row.find_all(\"td\")\n",
        "        if len(cols) >= 3:\n",
        "            city = cols[0].text.strip()\n",
        "            temperature = cols[1].text.strip()\n",
        "            condition = cols[2].text.strip()\n",
        "\n",
        "            all_weather_data.append({\n",
        "                \"City\": city,\n",
        "                \"Temperature\": temperature,\n",
        "                \"Condition\": condition\n",
        "            })\n",
        "\n",
        "    return all_weather_data\n",
        "\n",
        "\n",
        "\n",
        "weather_data = scrape_weather()\n",
        "\n",
        "if weather_data:\n",
        "    df = pd.DataFrame(weather_data)\n",
        "    df.to_csv(\"weather.csv\", index=False)\n",
        "    print(\" Scraping complete! Data saved to weather.csv\")\n",
        "    print(df.head())\n",
        "else:\n",
        "    print(\"No data was scraped from Time and Date.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kmw-CIBZdCt4",
        "outputId": "a34f7755-fb8c-442f-cc89-489a2852fc76"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Scraping complete! Data saved to weather.csv\n",
            "          City   Temperature Condition\n",
            "0        Accra   Thu 5:57 pm          \n",
            "1  Addis Ababa   Thu 8:57 pm          \n",
            "2   Adelaide *   Fri 4:27 am          \n",
            "3      Algiers   Thu 6:57 pm          \n",
            "4       Almaty  Thu 10:57 pm          \n"
          ]
        }
      ]
    }
  ]
}